{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lessons\n",
    "\n",
    "## Import main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sequential NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNNTest(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call the parent class constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNNTest(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNNTest().double()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 2]) | Values : tensor([[ 0.3918, -0.4192],\n",
      "        [-0.0935, -0.6215]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0016, 0.4560], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0012, -0.0155, -0.0234,  ..., -0.0207,  0.0199, -0.0402],\n",
      "        [ 0.0252,  0.0330, -0.0322,  ...,  0.0248, -0.0226, -0.0202]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0050, -0.0338], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([1, 512]) | Values : tensor([[ 3.1476e-02, -3.1610e-02,  3.2460e-02, -1.2747e-02,  3.1212e-02,\n",
      "          3.7826e-03,  3.4373e-02, -3.5654e-02,  4.6551e-03, -9.2084e-04,\n",
      "         -8.2455e-03, -2.0969e-02,  2.0928e-02,  6.4402e-03, -8.7342e-03,\n",
      "          4.5322e-03, -4.2088e-02, -4.9246e-03,  4.4367e-03,  2.2759e-02,\n",
      "          3.9460e-02, -2.5464e-02,  2.6440e-02, -3.6145e-02, -4.4053e-03,\n",
      "          3.6275e-02,  2.8282e-02, -1.1929e-02,  1.5820e-03, -1.2302e-02,\n",
      "          2.3125e-02, -2.5229e-02, -6.6545e-04,  3.9369e-02, -3.4318e-02,\n",
      "         -2.3996e-02, -2.7092e-02, -1.5939e-02, -2.3566e-02, -1.5785e-02,\n",
      "         -9.1888e-03, -2.1202e-02,  2.4011e-02,  3.9153e-05,  3.2057e-03,\n",
      "         -2.6658e-02, -1.3827e-02, -4.9141e-03, -3.1034e-02,  2.8938e-02,\n",
      "         -2.6991e-02,  1.3490e-02, -3.8376e-02, -3.1202e-02,  3.1468e-02,\n",
      "          3.1499e-02, -3.5245e-02, -2.2139e-02, -2.9822e-02, -4.0417e-02,\n",
      "         -2.0224e-02, -9.2883e-03,  4.1700e-02,  2.4833e-02,  3.5154e-02,\n",
      "          3.4702e-02, -4.0641e-02,  3.4983e-02,  3.6446e-02, -1.5555e-02,\n",
      "         -3.9217e-02, -1.4833e-02,  2.6921e-02,  1.3065e-02,  5.8726e-03,\n",
      "          2.7282e-02,  3.6183e-02,  8.5758e-03, -1.8989e-02,  1.6611e-02,\n",
      "         -3.6028e-02, -1.1998e-02, -1.7854e-03,  7.8463e-03, -1.1939e-02,\n",
      "         -2.8359e-02,  3.9996e-02,  2.1313e-02, -2.5049e-02,  1.4096e-02,\n",
      "         -3.5337e-02, -4.0307e-02, -1.7273e-02,  1.6326e-02, -2.3526e-02,\n",
      "         -1.7068e-02, -2.0178e-02,  1.1592e-02,  2.9890e-02,  4.0589e-02,\n",
      "          4.0980e-02,  2.6159e-02,  1.6542e-03,  3.9940e-02, -3.5072e-03,\n",
      "          4.2551e-02,  3.1626e-02,  2.5603e-02, -2.2011e-02, -2.4131e-02,\n",
      "          1.3157e-02,  3.1443e-02, -4.2740e-02, -1.8499e-02,  3.4490e-02,\n",
      "          4.1203e-02, -2.0401e-02, -3.0308e-02,  2.6615e-02,  3.4459e-02,\n",
      "          4.4378e-03,  4.0183e-02, -2.6921e-02, -8.6642e-03, -2.6025e-02,\n",
      "          2.4534e-02,  3.0262e-02, -3.0996e-02, -4.0437e-02,  4.1802e-02,\n",
      "          1.0909e-02, -4.1150e-02,  6.0355e-03,  2.8298e-02,  1.0542e-02,\n",
      "         -1.0399e-02, -3.2659e-02,  3.8941e-02, -2.0596e-03,  8.2799e-04,\n",
      "         -2.3772e-02,  2.0830e-02,  3.7432e-02, -7.7760e-03,  2.3769e-02,\n",
      "         -2.0023e-02, -3.8281e-02,  7.7061e-03, -2.9288e-02, -4.2102e-02,\n",
      "         -3.5441e-02, -3.9396e-03, -2.8181e-02, -2.6499e-02,  1.4142e-02,\n",
      "          4.2639e-02,  9.1713e-03, -2.2051e-02, -2.0442e-02, -4.1549e-02,\n",
      "         -3.4470e-02,  2.6634e-02, -1.5437e-02,  3.6494e-02,  3.2322e-02,\n",
      "          4.1421e-02, -4.2752e-03, -4.4022e-02,  3.3401e-02,  1.9906e-02,\n",
      "          2.5654e-02,  4.0797e-02, -2.0700e-02,  2.9108e-02, -3.0895e-02,\n",
      "          2.0746e-02, -2.0250e-02, -3.3440e-02,  2.3965e-02,  4.4165e-02,\n",
      "         -1.4761e-02,  2.4617e-02,  2.4876e-02,  3.8805e-02,  1.5239e-02,\n",
      "         -1.5839e-02, -3.2612e-02, -4.0313e-02,  1.0667e-03,  4.0154e-02,\n",
      "          3.5810e-02,  1.6197e-02,  3.7441e-02,  1.1071e-02, -1.7975e-02,\n",
      "          2.9622e-02,  3.6005e-02, -1.1833e-02, -3.6374e-02,  9.2027e-03,\n",
      "         -1.6366e-02, -3.6581e-02, -8.9890e-03,  1.3607e-02,  9.5423e-03,\n",
      "          3.9843e-02, -5.4895e-03, -3.8840e-02, -9.1791e-03, -1.7845e-02,\n",
      "          3.1836e-02,  3.9741e-02, -2.8242e-03,  2.8438e-02, -1.1533e-02,\n",
      "          2.7233e-02, -1.7877e-02, -3.3085e-02,  3.2015e-02, -3.8448e-02,\n",
      "         -1.4031e-02,  1.1583e-02, -8.3062e-03, -3.1107e-02, -1.4039e-03,\n",
      "         -4.1912e-02, -5.5385e-03,  6.2080e-03, -3.5294e-02, -2.4580e-02,\n",
      "         -4.0196e-02, -3.5529e-02,  3.4803e-02, -3.1440e-02, -1.9805e-02,\n",
      "         -4.9622e-03, -2.3297e-02, -1.3260e-02,  3.4343e-02,  4.0868e-02,\n",
      "         -3.3706e-02, -1.9065e-02,  1.9934e-02, -7.6030e-03,  1.6956e-02,\n",
      "          2.2734e-02, -3.9258e-02,  3.2494e-02,  3.5107e-02,  1.4522e-02,\n",
      "          1.5123e-02,  3.5270e-02, -3.3869e-02,  3.4922e-02,  1.8732e-02,\n",
      "         -2.8228e-02, -8.1722e-03, -4.3284e-02,  3.3368e-03,  8.3065e-03,\n",
      "          2.2095e-02, -2.8042e-02, -9.7439e-03,  4.3238e-03,  7.8499e-03,\n",
      "         -2.5202e-02, -4.1447e-02,  4.1672e-02, -5.2813e-03,  3.0243e-02,\n",
      "         -3.9220e-02, -1.3244e-02, -2.3166e-02, -1.7642e-02, -3.5096e-02,\n",
      "         -2.5749e-02,  1.8733e-02, -2.7220e-03,  5.4138e-03, -4.6119e-03,\n",
      "         -1.9372e-02, -1.1893e-02, -3.3593e-02,  1.1590e-02, -3.8806e-02,\n",
      "          4.3219e-02,  1.5002e-02, -3.1779e-02,  3.5507e-03, -4.1388e-02,\n",
      "         -8.5000e-03,  4.2454e-02, -3.7409e-02, -3.8509e-02,  3.5304e-02,\n",
      "         -4.3013e-02,  2.8586e-02, -2.4352e-02, -1.0571e-02,  2.1234e-02,\n",
      "          2.5630e-02, -1.6958e-02,  2.2169e-02,  2.7801e-04,  1.8814e-02,\n",
      "         -4.0496e-02,  3.6920e-02,  4.2267e-02, -2.6183e-02, -3.7164e-02,\n",
      "         -4.2296e-03,  2.6771e-02,  1.6922e-02,  4.1648e-02,  2.9349e-02,\n",
      "         -3.1552e-02,  8.2156e-03,  2.3618e-02, -4.3013e-02,  7.4353e-03,\n",
      "          1.4214e-02,  2.5762e-02,  3.5534e-02,  2.5187e-03, -1.0102e-02,\n",
      "         -3.9081e-03,  1.9281e-02,  2.9120e-02, -2.4479e-02, -9.1556e-03,\n",
      "          3.9799e-02,  2.4182e-02, -3.7331e-02, -3.2975e-03, -1.0568e-02,\n",
      "         -3.2371e-02,  2.4711e-02,  1.5052e-02, -3.9924e-05,  4.4192e-02,\n",
      "         -3.1964e-03,  2.5308e-02, -1.7545e-02, -2.4533e-02,  3.0287e-02,\n",
      "         -4.1305e-02,  4.3383e-02,  4.3926e-02, -8.7882e-03, -3.8329e-02,\n",
      "         -1.8333e-02,  1.9925e-03,  4.3009e-02, -2.6016e-02,  1.6864e-02,\n",
      "          6.0136e-03, -4.3259e-02, -3.7850e-02,  1.0796e-02,  3.9648e-03,\n",
      "          4.3983e-02, -1.4477e-02, -3.8688e-02,  1.6901e-02, -2.7473e-02,\n",
      "         -1.8292e-02, -3.6612e-02, -4.0625e-02,  2.5062e-03, -4.0959e-02,\n",
      "          4.2597e-02,  4.4493e-03,  1.2907e-02, -1.5519e-02,  5.3978e-03,\n",
      "         -2.8956e-02,  3.7573e-02, -3.0096e-02, -4.1289e-02,  1.8304e-02,\n",
      "          4.1356e-02, -2.6089e-02,  1.6531e-03,  8.8740e-03, -3.9160e-02,\n",
      "          2.6146e-02, -6.0932e-03,  1.1672e-02, -5.8168e-03,  9.2642e-03,\n",
      "          2.4008e-02,  3.1864e-02, -3.4858e-02,  2.8609e-02,  3.0269e-02,\n",
      "         -8.2542e-03, -7.6784e-03, -1.0803e-02, -4.1896e-02,  3.2243e-03,\n",
      "          1.0588e-02, -2.8337e-02, -1.0487e-02, -4.0264e-02, -3.7632e-02,\n",
      "          2.8047e-02,  1.6533e-02,  7.1884e-04, -3.6984e-02,  1.3361e-02,\n",
      "         -9.4080e-03, -3.3794e-02,  4.6844e-04, -2.3588e-02,  2.2059e-02,\n",
      "         -3.7532e-03,  3.0764e-02,  1.1175e-02, -1.0795e-02, -3.1914e-02,\n",
      "          1.3167e-03,  1.0164e-02, -1.3103e-02, -1.2843e-02, -3.6651e-03,\n",
      "         -2.0473e-02, -4.0933e-02, -2.5327e-02,  2.8918e-02, -8.1966e-03,\n",
      "          4.0174e-02, -3.6459e-02,  1.2482e-02, -4.0176e-02,  3.9318e-02,\n",
      "          2.0260e-02, -2.6524e-02,  2.8053e-03, -3.0635e-02,  2.9515e-02,\n",
      "          4.1868e-02, -1.9685e-02,  2.9500e-02,  3.5202e-02, -1.2182e-02,\n",
      "          1.3048e-02,  6.1494e-03,  3.0256e-02,  2.6055e-02,  3.4338e-02,\n",
      "          1.2600e-03,  4.2042e-02,  1.0762e-02,  1.9167e-02, -4.6350e-03,\n",
      "          3.5429e-02, -2.4928e-02,  2.2888e-02,  6.0527e-03,  3.9508e-02,\n",
      "         -2.2591e-02, -5.3028e-04, -1.5837e-02,  4.2215e-02,  2.7918e-02,\n",
      "         -4.4074e-02, -6.4040e-03,  3.8718e-03,  2.5971e-02, -2.7575e-02,\n",
      "         -4.3836e-02,  4.2537e-02,  8.6082e-03,  2.6905e-02,  3.2815e-02,\n",
      "          1.9955e-02, -1.7572e-02, -2.2504e-04,  2.7033e-03,  2.9410e-02,\n",
      "          3.2699e-04,  1.4754e-02, -8.0274e-03, -2.3100e-02,  2.0234e-02,\n",
      "         -6.1236e-03, -1.6630e-03, -3.6920e-03, -6.6998e-03, -6.1921e-03,\n",
      "         -1.3867e-02,  1.3131e-02,  1.0799e-02,  2.0801e-02, -3.4428e-02,\n",
      "         -3.0708e-02, -1.8255e-02,  1.3801e-02,  1.5439e-03, -1.5304e-02,\n",
      "          2.3149e-03,  3.1282e-02,  3.3005e-02,  1.8482e-02, -2.9271e-02,\n",
      "         -1.5835e-02, -2.1014e-02,  4.0665e-02, -2.0154e-02,  3.1876e-02,\n",
      "          9.2636e-03, -2.1515e-02]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([1]) | Values : tensor([-0.0177], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3918, -0.4192],\n",
       "        [-0.0935, -0.6215],\n",
       "        [ 0.4750, -0.5103],\n",
       "        ...,\n",
       "        [-0.6251,  0.2925],\n",
       "        [ 0.2232,  0.3493],\n",
       "        [-0.3443, -0.4862]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['linear_relu_stack.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 0.3 # error term\n",
    "num = 20000 #num poins\n",
    "\n",
    "X = np.random.uniform(-4*np.pi,4*np.pi, (num,1))\n",
    "Y = np.random.uniform(-4*np.pi,4*np.pi, (num,1))\n",
    "\n",
    "XXX = np.hstack((X,Y))\n",
    "\n",
    "Z = np.sin(np.sqrt(X**2+Y**2))+ ep*np.random.normal(0,1,(num,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
