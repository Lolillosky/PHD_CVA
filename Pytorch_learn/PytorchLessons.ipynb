{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lessons\n",
    "\n",
    "## Import main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Creating tensors and some tensor attibutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element of a tensor:\n",
      "tensor(-0.3210, dtype=torch.float64)\n",
      "Numpy content\n",
      "[[-3.20984841e-01  8.68230526e-01  1.69571487e+00  7.23955389e-04\n",
      "   3.36589140e-01 -8.83360495e-01  1.32287358e+00 -2.60220435e+00\n",
      "  -1.33808755e-01  9.67779373e-01]\n",
      " [ 1.14607866e+00 -1.54071085e-02 -3.05711900e+00  4.54577189e-01\n",
      "  -5.63976211e-01 -6.68318696e-02  1.78632671e+00  7.98796518e-01\n",
      "  -6.11990172e-01  2.91468530e-01]\n",
      " [ 1.21132031e+00  9.45054357e-01 -2.15669023e+00  1.50055839e+00\n",
      "  -2.06740392e+00  1.95280175e+00 -1.25718760e+00 -1.23448567e+00\n",
      "   3.50098188e-01  9.84948695e-01]\n",
      " [-8.15555341e-01  9.27113340e-01  3.10052272e-01  1.23870895e+00\n",
      "  -1.94882224e+00  9.04650961e-01  1.84186024e+00  1.81202203e+00\n",
      "  -8.69199444e-02 -2.02965402e-01]\n",
      " [-8.56140589e-02  4.19903002e-02 -1.67506840e+00  1.48131658e+00\n",
      "   1.79499347e+00 -1.17870425e+00  2.78287339e-01 -2.66689860e-01\n",
      "   5.80595437e-02 -1.97701066e+00]\n",
      " [ 4.89294977e-01 -7.73010833e-01  1.33729802e-01  1.01537817e+00\n",
      "  -6.96437630e-01  3.21518984e-01  3.18668814e-01  7.41519431e-01\n",
      "   1.01690615e-01 -4.01294029e-01]\n",
      " [ 1.43434450e+00  5.11992747e-01  5.85256253e-01 -1.25003586e-01\n",
      "   4.78445220e-01  1.17202711e-01  6.02167382e-01 -2.02723070e-01\n",
      "   4.19490774e-01 -1.79557479e-01]\n",
      " [ 2.74067276e-01  2.76168887e-02 -2.60967553e-01  6.14120495e-01\n",
      "   3.44934627e-01 -2.88746909e-04 -1.95139208e+00 -7.54125034e-01\n",
      "   1.45007660e+00 -1.14622650e+00]\n",
      " [ 3.57886928e-01 -1.09514378e+00 -1.29235270e+00 -1.85237560e-02\n",
      "   1.19274613e+00 -4.20877330e-01 -1.27652581e-01 -2.80883409e-01\n",
      "  -3.72338392e-01 -1.81327603e-01]\n",
      " [-2.92958474e-01  1.14530736e+00  2.55360728e+00  2.05150855e+00\n",
      "   7.30732468e-01  8.21563687e-01  1.47732228e+00 -8.30291289e-01\n",
      "   1.01767739e+00  2.11013485e+00]]\n",
      "Device\n",
      "cpu\n",
      "Shape\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor from numpy array:\n",
    "\n",
    "X = np.random.normal(0,1,(10,10))\n",
    "X = torch.tensor(X, dtype=torch.float64)\n",
    "\n",
    "\n",
    "print('Element of a tensor:')\n",
    "print(X[0,0])\n",
    "print('Numpy content')\n",
    "print(X.numpy())\n",
    "print('Device')\n",
    "print(X.device)\n",
    "print('Shape')\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of two tensors:\n",
      "tensor([[11., 13., 15.],\n",
      "        [17., 19., 21.],\n",
      "        [23., 25., 27.]], dtype=torch.float64)\n",
      "Tensor multiplication:\n",
      "tensor([[ 84.,  90.,  96.],\n",
      "        [201., 216., 231.],\n",
      "        [318., 342., 366.]], dtype=torch.float64)\n",
      "Tensor transpose:\n",
      "tensor([[ 84., 201., 318.],\n",
      "        [ 90., 216., 342.],\n",
      "        [ 96., 231., 366.]], dtype=torch.float64)\n",
      "Tensor multiplication:\n",
      "tensor([[ 84.,  90.,  96.],\n",
      "        [201., 216., 231.],\n",
      "        [318., 342., 366.]], dtype=torch.float64)\n",
      "Mean:\n",
      "tensor(5., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.tensor(np.arange(1,10).reshape(3,3), dtype=torch.float64)\n",
    "b = torch.tensor(np.arange(10,19).reshape(3,3), dtype=torch.float64)\n",
    "\n",
    "print('Sum of two tensors:')\n",
    "print(a+b)\n",
    "print('Tensor multiplication:')\n",
    "print(a @ b)\n",
    "print('Tensor transpose:')\n",
    "print((a @ b).T)\n",
    "print('Tensor multiplication:')\n",
    "print(torch.matmul(a,b))\n",
    "print('Mean:')\n",
    "print(torch.mean(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inline operators have a _ in the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]], dtype=torch.float64)\n",
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]], dtype=torch.float64)\n",
      "tensor([[ 6.,  9., 12.],\n",
      "        [ 7., 10., 13.],\n",
      "        [ 8., 11., 14.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "a.transpose_(0,1)\n",
    "print(a)\n",
    "a.add_(5.0)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]], dtype=torch.int32)\n",
      "tensor([[4, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]], dtype=torch.int32)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# In CPU\n",
    "a = np.arange(1,10).reshape(3,3)\n",
    "print(a)\n",
    "t = torch.from_numpy(a)\n",
    "print(t)\n",
    "a[0,0] = 4\n",
    "print(t)\n",
    "\n",
    "t_ = torch.ones(3,3)\n",
    "\n",
    "print(t_)\n",
    "\n",
    "n_ = t_.numpy()\n",
    "\n",
    "n_[0,0] = 5.0\n",
    "\n",
    "print(t_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "To implement a custom dataset, we use simulated data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000\n",
    "ep = 0.1\n",
    "\n",
    "x = np.random.uniform(-4*np.pi,4*np.pi,(num,2))\n",
    "\n",
    "y = np.sin(np.sqrt(x[:,0]**2+x[:,1]**2))+ ep*np.random.normal(0,1,num)\n",
    "\n",
    "\n",
    "np.save('../DATA/x.npy', x)\n",
    "np.save('../DATA/y.npy', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_file, y_file):\n",
    "        # Class constructor:\n",
    "        # Loads the dataset from files:\n",
    "        self.x = torch.tensor(np.load(x_file), dtype=torch.float64)\n",
    "        self.y = torch.tensor(np.load(y_file), dtype=torch.float64)\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieves an item from the dataset:\n",
    "        # In very big daytasets, we should not load all data at once.\n",
    "\n",
    "        return self.x[index], self.y[index]\n",
    "        # TODO: convert to tensor \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Returns the length of the dataset:\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6333,  5.1755], dtype=torch.float64),\n",
       " tensor(-0.8434, dtype=torch.float64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CustomDataset('../DATA/x.npy', '../DATA/y.npy')\n",
    "\n",
    "data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "v = np.arange(1,10)\n",
    "\n",
    "it = iter(v)\n",
    "\n",
    "print(next(it))\n",
    "print(next(it))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.7311, -11.5765],\n",
      "        [-10.5169,   4.1648],\n",
      "        [ -6.3972,   6.7122],\n",
      "        [ -5.4248,  -8.1511],\n",
      "        [ -9.0625, -10.9561],\n",
      "        [  5.7612, -10.9601],\n",
      "        [  4.4158,  -6.0960],\n",
      "        [ -3.3264,  -2.8247],\n",
      "        [  0.7254,  12.0318],\n",
      "        [ -1.8539,  -1.6790],\n",
      "        [ -3.1678,  -6.5105],\n",
      "        [ 12.3219,  -7.3169],\n",
      "        [  0.3138,  -4.3331],\n",
      "        [  5.3345,  -7.1468],\n",
      "        [  4.0946,  12.0322],\n",
      "        [ -0.7887,  -7.3680],\n",
      "        [ -1.1501,  11.6483],\n",
      "        [ 10.5947,  -3.1375],\n",
      "        [  6.2599,  -0.4490],\n",
      "        [  5.5620,  -4.5110],\n",
      "        [  7.6231,  -3.6295],\n",
      "        [  1.8677,   2.1292],\n",
      "        [ 11.3650,   0.1732],\n",
      "        [ -9.0614,   6.9214],\n",
      "        [ -2.6314,  -4.2140],\n",
      "        [  0.9515,  -0.4879],\n",
      "        [  3.7065,   2.5193],\n",
      "        [  6.3062,   9.2012],\n",
      "        [  1.9532,   2.4848],\n",
      "        [ 10.4019,  11.3704],\n",
      "        [ 10.6115,   0.8548],\n",
      "        [ -1.5488,   2.0761],\n",
      "        [ -6.2376,  -8.8461],\n",
      "        [ -6.5366,  -3.6696],\n",
      "        [  9.9755,  -0.1022],\n",
      "        [  1.0742,  -2.6967],\n",
      "        [-11.9184,   4.6531],\n",
      "        [  3.0387,  -3.3755],\n",
      "        [-11.5098, -10.1917],\n",
      "        [ -3.1654,   3.6722],\n",
      "        [  5.3399,   6.6763],\n",
      "        [  2.4163,   6.1229],\n",
      "        [ -9.6253,   3.7651],\n",
      "        [ -9.9708,  -9.7643],\n",
      "        [  8.5295,  -7.2983],\n",
      "        [ -7.9516,   4.7024],\n",
      "        [  0.8352,  -4.6827],\n",
      "        [ -3.1637,   3.3604],\n",
      "        [-12.1130,   9.0444],\n",
      "        [ 12.3566,   0.8892],\n",
      "        [-10.3262,  -1.5898],\n",
      "        [  0.1885,  -8.8969],\n",
      "        [  2.7499,  -4.4539],\n",
      "        [  3.9001, -12.4532],\n",
      "        [ 11.1497,  -4.0337],\n",
      "        [ -9.1033,  -0.5487],\n",
      "        [  7.7937,  -5.2116],\n",
      "        [  3.6502,   6.6431],\n",
      "        [ -8.7401,  -4.3791],\n",
      "        [  2.7338,  -7.5392],\n",
      "        [ -2.1608,   0.4357],\n",
      "        [ -4.2378,  10.9815],\n",
      "        [ 10.3684,  -6.3652],\n",
      "        [ 11.9350,  -1.4431]], dtype=torch.float64)\n",
      "tensor([ 0.7897, -1.0197,  0.1879, -0.3015,  0.9974, -0.2386,  0.9914, -1.1157,\n",
      "        -0.4313,  0.5938,  0.8484,  1.0223, -0.9115,  0.4131,  0.2715,  0.9896,\n",
      "        -0.6513, -1.0340, -0.1606,  0.7601,  0.8725,  0.3447, -0.8365, -0.7700,\n",
      "        -1.0493,  1.0273, -0.8707, -0.8449, -0.0750,  0.1276, -0.9523,  0.5141,\n",
      "        -1.0072,  0.9551, -0.5097,  0.3462,  0.1336, -1.0297,  0.2457, -1.1834,\n",
      "         0.8468,  0.2985, -0.8250,  1.0509, -0.9746,  0.2099, -1.0434, -1.0253,\n",
      "         0.5806, -0.0118, -0.8116,  0.3730, -0.9870,  0.4420, -0.6183,  0.2601,\n",
      "        -0.0210,  1.0292, -0.3563,  0.9818,  0.7086, -0.7781, -0.4247, -0.5275],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(data, batch_size=64, shuffle=True)\n",
    "\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "print(x_batch)\n",
    "\n",
    "print(y_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sequential NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNNTest(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call the parent class constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNNTest(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# If we wanted to use GPU, we should check if it is available:\n",
    "# model = NeuralNetwork().to(device)  \n",
    "\n",
    "# To use double precision:\n",
    "model = MyNNTest().double()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7313],\n",
       "        [ 0.4378],\n",
       "        [ 0.1765],\n",
       "        [ 0.5588],\n",
       "        [ 0.7775],\n",
       "        [ 1.1073],\n",
       "        [ 0.7208],\n",
       "        [ 0.3034],\n",
       "        [ 0.2777],\n",
       "        [ 0.2098],\n",
       "        [ 0.4122],\n",
       "        [ 0.9344],\n",
       "        [ 0.3474],\n",
       "        [ 0.8318],\n",
       "        [ 0.1866],\n",
       "        [ 0.4400],\n",
       "        [ 0.2770],\n",
       "        [ 0.2955],\n",
       "        [ 0.0129],\n",
       "        [ 0.6220],\n",
       "        [ 0.4723],\n",
       "        [-0.0031],\n",
       "        [-0.1300],\n",
       "        [ 0.2899],\n",
       "        [ 0.3045],\n",
       "        [ 0.1086],\n",
       "        [-0.0566],\n",
       "        [ 0.0646],\n",
       "        [ 0.0023],\n",
       "        [ 0.0756],\n",
       "        [-0.1810],\n",
       "        [ 0.0535],\n",
       "        [ 0.6177],\n",
       "        [ 0.4258],\n",
       "        [-0.0832],\n",
       "        [ 0.3317],\n",
       "        [ 0.4906],\n",
       "        [ 0.4608],\n",
       "        [ 0.8545],\n",
       "        [ 0.0893],\n",
       "        [ 0.0271],\n",
       "        [ 0.0914],\n",
       "        [ 0.4068],\n",
       "        [ 0.7942],\n",
       "        [ 0.9437],\n",
       "        [ 0.2914],\n",
       "        [ 0.4249],\n",
       "        [ 0.0934],\n",
       "        [ 0.3803],\n",
       "        [-0.2090],\n",
       "        [ 0.5110],\n",
       "        [ 0.5873],\n",
       "        [ 0.5395],\n",
       "        [ 1.1244],\n",
       "        [ 0.4278],\n",
       "        [ 0.4667],\n",
       "        [ 0.6952],\n",
       "        [ 0.0646],\n",
       "        [ 0.5095],\n",
       "        [ 0.7498],\n",
       "        [ 0.1185],\n",
       "        [ 0.2598],\n",
       "        [ 0.8287],\n",
       "        [ 0.0423]], dtype=torch.float64, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 2]) | Values : tensor([[-0.1375, -0.3483],\n",
      "        [-0.4689,  0.2882]], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.3899, -0.2300], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0316, -0.0199,  0.0041,  ...,  0.0375,  0.0383, -0.0408],\n",
      "        [ 0.0094, -0.0289,  0.0221,  ...,  0.0335,  0.0338, -0.0210]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0317,  0.0288], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([1, 512]) | Values : tensor([[-4.3247e-03,  3.2663e-03,  4.3945e-02,  3.3910e-02, -2.4253e-02,\n",
      "         -1.7908e-02, -6.9334e-03,  1.3841e-02,  3.0994e-02,  8.2276e-03,\n",
      "         -1.8599e-02, -1.3894e-02,  1.6065e-02,  5.6081e-03, -3.9836e-02,\n",
      "          5.3520e-03, -1.2960e-02,  4.3938e-03, -3.8378e-02, -9.8830e-03,\n",
      "         -1.7111e-02,  3.5500e-03,  3.2002e-02,  1.5608e-03, -6.9093e-03,\n",
      "          2.2231e-03,  1.7538e-02, -5.1611e-03,  3.1175e-02, -2.6411e-03,\n",
      "         -3.0248e-02,  3.1089e-02, -3.7575e-02,  3.6153e-02,  2.4360e-02,\n",
      "          2.4261e-02,  2.9512e-02,  3.6934e-03, -4.2511e-02,  2.0408e-02,\n",
      "          4.2886e-04, -3.2152e-02,  2.4238e-02, -3.9518e-02,  2.5228e-02,\n",
      "         -1.6767e-02,  1.9731e-02, -1.6354e-02,  3.5735e-02, -1.4680e-02,\n",
      "         -2.7910e-02,  9.5566e-03,  1.7865e-02,  4.0393e-02, -3.5666e-02,\n",
      "         -9.8393e-03,  2.4553e-02,  2.9329e-02,  2.2736e-02,  4.2485e-02,\n",
      "          1.7703e-02,  2.2695e-02, -1.3668e-02, -3.8095e-02, -2.8873e-02,\n",
      "         -5.1633e-06,  3.5986e-02,  2.4886e-02, -7.6231e-03, -1.0006e-02,\n",
      "         -2.3034e-02,  1.8683e-02,  8.0090e-03, -2.6677e-02, -1.6087e-02,\n",
      "         -3.2157e-03,  4.2146e-02,  5.7593e-03,  1.6409e-02, -3.6944e-03,\n",
      "         -1.3497e-02,  2.3609e-02,  4.3863e-02,  1.6276e-02,  6.3969e-03,\n",
      "         -1.9795e-02, -1.1007e-02, -2.6822e-02, -6.6417e-03,  1.2123e-02,\n",
      "          1.2520e-02, -2.7710e-02, -2.9049e-02, -2.2857e-02,  3.7697e-02,\n",
      "         -6.7315e-03,  1.5844e-02,  2.9124e-02,  2.2469e-02,  5.1231e-03,\n",
      "          3.8453e-02,  2.5358e-03, -3.4761e-02, -1.1794e-02,  1.6977e-02,\n",
      "          1.9269e-02,  1.0632e-02, -2.9373e-03, -1.5823e-02,  3.0153e-02,\n",
      "          4.0348e-02,  9.6289e-03,  2.1829e-02,  3.8835e-03,  3.7939e-02,\n",
      "          1.5510e-02, -1.0399e-02, -4.1839e-02,  8.2195e-03, -1.1424e-02,\n",
      "         -2.6643e-02, -1.3173e-02, -2.3426e-04, -2.5623e-02, -2.2137e-02,\n",
      "          2.1458e-02,  3.2399e-02, -2.2738e-02,  1.3312e-02, -3.0844e-02,\n",
      "          1.1111e-02,  3.9145e-02,  4.1391e-02, -2.4170e-02,  4.3708e-02,\n",
      "         -4.1446e-02,  2.1388e-02, -9.9496e-03, -4.0430e-02,  7.0480e-03,\n",
      "          3.5501e-03, -2.6974e-02, -3.9406e-02, -2.6620e-02,  8.7148e-03,\n",
      "         -5.3718e-04, -2.6620e-02,  2.6619e-02, -6.1903e-03,  3.7027e-02,\n",
      "          1.8614e-02,  4.1490e-03,  4.0428e-02,  1.0283e-02, -4.0658e-02,\n",
      "          2.2578e-02,  2.2661e-02, -1.8772e-03, -7.7809e-03,  1.9789e-02,\n",
      "         -1.1531e-02,  2.7422e-02, -2.4559e-02,  4.0453e-02, -4.1448e-02,\n",
      "          2.7388e-02,  3.4418e-02, -7.2053e-03,  1.2242e-02,  3.2372e-02,\n",
      "         -3.3541e-02, -1.1617e-02, -3.3801e-02,  4.3481e-02,  7.1555e-04,\n",
      "         -1.5542e-02, -1.0184e-03,  2.8051e-02, -9.7686e-03,  6.2205e-03,\n",
      "          2.3628e-02, -2.3398e-03, -2.7306e-02, -2.9265e-02,  4.4052e-02,\n",
      "          1.1853e-02, -3.1421e-02,  2.2133e-02,  2.0653e-02, -6.6784e-03,\n",
      "          3.2388e-02,  8.3058e-03, -3.2093e-02, -3.9847e-02, -1.7163e-02,\n",
      "          2.0463e-02, -3.7934e-02,  3.5611e-02,  3.4622e-02,  2.6382e-02,\n",
      "         -1.6742e-02,  1.3667e-02, -1.3400e-02, -1.9668e-02,  2.9493e-02,\n",
      "         -5.3200e-03, -1.0665e-02, -2.4956e-02, -4.6668e-03, -1.0104e-02,\n",
      "          9.2799e-03,  5.0663e-03, -3.5725e-02, -3.3975e-02,  4.0237e-02,\n",
      "          4.1322e-02, -3.6454e-02, -1.4048e-02,  1.5437e-02, -3.4458e-02,\n",
      "          3.3799e-02, -3.0856e-02, -3.1654e-02,  2.4674e-02,  2.5008e-02,\n",
      "         -5.1225e-03, -4.1529e-02,  3.8762e-02, -5.2800e-03,  3.7703e-02,\n",
      "         -2.1205e-02,  1.5876e-02, -5.1556e-03,  3.3319e-02, -1.8173e-02,\n",
      "         -2.6729e-02,  1.8273e-03, -4.1393e-02,  1.9690e-02, -1.3033e-02,\n",
      "          3.6283e-02,  5.9674e-03,  4.3759e-03, -4.0336e-02,  4.2894e-02,\n",
      "          2.6730e-02, -3.6471e-02, -1.9519e-02,  2.8267e-02, -2.0024e-02,\n",
      "          9.7540e-03,  3.5647e-02, -3.5039e-02,  2.1271e-02, -4.3184e-02,\n",
      "         -4.5797e-03,  3.9954e-02,  1.9635e-02, -9.7491e-03, -2.5067e-02,\n",
      "          1.3160e-02, -5.7032e-04, -6.9980e-03,  7.1422e-03, -1.3706e-02,\n",
      "         -1.7496e-02, -1.8839e-02, -1.3723e-02, -1.4866e-02,  5.0290e-03,\n",
      "         -3.2335e-02, -3.7609e-02, -3.1424e-02,  2.2469e-02, -5.1676e-03,\n",
      "          3.5112e-02,  2.4995e-02, -2.6000e-02, -3.7622e-02, -3.9188e-02,\n",
      "         -2.5252e-02, -3.5046e-02,  1.5537e-02,  5.6375e-03,  2.4238e-03,\n",
      "          8.3634e-03, -3.9660e-02,  2.5069e-02, -1.6653e-02,  6.4013e-03,\n",
      "          2.2945e-02, -9.9267e-03, -3.0969e-02, -6.0479e-03, -3.6953e-02,\n",
      "         -3.2242e-02, -4.2777e-02, -3.6147e-02,  1.5759e-02, -2.9391e-02,\n",
      "         -2.1997e-02, -2.6785e-02,  8.0858e-03,  2.9643e-02,  3.2224e-02,\n",
      "         -1.6506e-02, -3.1037e-02, -4.1583e-02, -1.3826e-02,  2.5804e-02,\n",
      "          1.1252e-02, -1.8049e-02, -3.3941e-02, -1.5127e-02,  2.3957e-03,\n",
      "         -2.1294e-02,  4.3308e-02,  3.8966e-02, -1.3399e-02,  6.6868e-03,\n",
      "          2.7432e-02, -1.7906e-02,  1.5576e-02,  1.5757e-02,  2.8784e-02,\n",
      "          2.1876e-03, -2.8062e-02,  3.1068e-02, -1.5388e-02, -8.6769e-03,\n",
      "          3.0105e-02,  3.2041e-02,  9.6368e-03, -2.5593e-02, -5.7981e-03,\n",
      "          2.2642e-02, -4.2573e-02,  2.6522e-02,  3.7297e-02, -1.2287e-02,\n",
      "          3.4855e-02,  8.2819e-03, -2.8810e-02, -3.4783e-03,  6.3110e-03,\n",
      "          4.0529e-02,  1.5011e-02,  7.7996e-03, -9.1997e-03, -4.3777e-02,\n",
      "         -4.6675e-03, -4.2980e-02,  2.6870e-03,  4.0578e-02, -1.7786e-03,\n",
      "          4.2260e-02,  1.2440e-02,  7.1714e-03, -2.6723e-02,  2.6263e-02,\n",
      "          3.7102e-04, -2.8084e-03,  1.2748e-02,  2.3085e-02,  3.1210e-02,\n",
      "         -3.8354e-02,  3.1372e-02,  3.1693e-02, -2.8156e-02, -2.1246e-02,\n",
      "          1.2582e-02,  7.9591e-03,  2.8130e-02, -2.6302e-02,  2.8338e-02,\n",
      "         -1.6409e-02, -3.6660e-02, -2.3514e-02, -4.1533e-02, -1.9035e-02,\n",
      "          3.3403e-02, -1.6985e-02, -1.2973e-03, -1.8013e-02, -5.8785e-03,\n",
      "         -2.6947e-02,  3.4557e-02,  2.2327e-02, -1.0472e-02,  1.5670e-02,\n",
      "          2.8376e-02,  5.3959e-03,  2.3435e-03,  1.6616e-02,  3.0454e-02,\n",
      "          3.6897e-02, -1.4720e-02, -2.0759e-02, -2.3586e-02,  1.0959e-02,\n",
      "         -1.0821e-02, -6.3859e-03, -8.5197e-06, -3.1977e-02,  9.6748e-03,\n",
      "          1.5820e-02, -1.7291e-02,  1.6257e-02,  3.0033e-02, -3.4059e-03,\n",
      "         -3.0093e-02,  1.8705e-02, -2.9518e-02, -3.2364e-03, -1.9353e-03,\n",
      "          3.0143e-02,  3.0387e-02,  1.1171e-02,  6.3604e-03, -3.4387e-02,\n",
      "          4.4632e-04,  2.2944e-02, -1.1616e-02, -1.0487e-02,  1.3470e-02,\n",
      "          1.2332e-02,  3.0668e-02,  1.2970e-02,  3.2013e-02, -1.9774e-02,\n",
      "         -2.1086e-02,  3.3434e-02,  3.1054e-03,  1.6159e-02,  1.1935e-02,\n",
      "          3.1780e-02,  3.4551e-02, -4.6483e-03,  3.7083e-02,  2.5721e-02,\n",
      "          2.3931e-02,  2.5311e-03,  6.0016e-04,  8.2959e-03, -2.1342e-02,\n",
      "          2.4208e-02,  1.8639e-02, -1.7269e-02, -1.6065e-02, -3.0009e-02,\n",
      "          1.3526e-02, -1.7186e-03,  2.8976e-02,  1.3660e-02,  1.5511e-02,\n",
      "          3.7377e-02, -2.0688e-02, -3.5961e-02,  9.2923e-03, -4.3790e-02,\n",
      "         -1.9128e-02, -3.7899e-02,  2.9578e-02,  2.9578e-02, -2.9347e-02,\n",
      "          4.2856e-03,  8.4583e-03,  4.1694e-02, -1.0897e-02,  3.9497e-02,\n",
      "          3.9981e-02, -3.6355e-02,  4.5135e-03,  2.5320e-02, -3.4592e-02,\n",
      "         -3.9861e-02,  4.0405e-02, -2.7190e-02,  2.3260e-02, -3.1617e-02,\n",
      "          2.9171e-02,  1.8129e-02,  2.4303e-02,  2.8873e-02, -3.9408e-02,\n",
      "          8.9797e-03,  1.6154e-02, -3.4505e-02,  1.8135e-02,  7.0134e-03,\n",
      "         -2.4137e-02,  2.4989e-02, -5.5312e-03,  1.2591e-02, -4.2601e-02,\n",
      "          3.6061e-02, -3.3600e-02,  2.6212e-03, -3.7274e-03, -1.9791e-02,\n",
      "          1.4754e-02,  7.4682e-03,  3.9441e-02,  2.2199e-02, -3.4395e-02,\n",
      "         -1.8750e-02,  4.1330e-02, -2.1971e-02, -1.0232e-02, -2.9866e-02,\n",
      "          2.4884e-02,  2.3992e-02]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([1]) | Values : tensor([0.0166], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to access model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1375, -0.3483],\n",
       "        [-0.4689,  0.2882],\n",
       "        [ 0.1755,  0.5304],\n",
       "        ...,\n",
       "        [-0.3554,  0.3871],\n",
       "        [ 0.1830,  0.0357],\n",
       "        [ 0.4002, -0.0649]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['linear_relu_stack.0.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto diff with torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.linspace(-4*np.pi,4*np.pi,100), dtype=torch.float64)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "definitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
