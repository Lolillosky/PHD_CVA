{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Lessons\n",
    "\n",
    "## Import main libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "Creating tensors and some tensor attibutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element of a tensor:\n",
      "tensor(-0.7236, dtype=torch.float64)\n",
      "Numpy content\n",
      "[[-0.72357882 -0.98200559  0.02147    -0.91033548  0.33333997  0.54313593\n",
      "   1.12440887  0.08147864 -0.02252688  0.2812191 ]\n",
      " [ 1.27805763 -1.09880695 -1.39086093  0.52215842 -0.35930462  0.20148094\n",
      "   1.10331915 -0.91412485  1.92440095  0.1008614 ]\n",
      " [ 0.773226    0.38981079 -0.98103216  0.64313986 -0.96939597  0.79740426\n",
      "   0.49371802  0.53984929  0.33192952  1.33570878]\n",
      " [-1.96221066 -0.57432703  0.67768535  1.71246152 -1.15014596  0.1724696\n",
      "   0.32380595  0.2608312   0.26907074  1.08583287]\n",
      " [ 1.86156917 -0.09163716 -0.1577448   0.173819    1.21666601 -1.28942697\n",
      "   0.82994133  1.73708082  0.01552051  0.80902603]\n",
      " [-0.35171488  0.5819074  -0.12761651 -0.11917034 -1.39278072 -0.36788984\n",
      "  -1.47612238  0.3830713  -1.11807131 -1.83443072]\n",
      " [ 1.6200243  -0.00262089  0.74011618  2.06623135  0.67678398 -0.44693814\n",
      "  -0.50125419  0.93866071  0.72019479  0.20478842]\n",
      " [ 1.68129694  1.07496465 -2.09703855  2.43402041 -0.40729448  0.42541868\n",
      "   0.60117093 -1.24612036  0.76948554  0.347073  ]\n",
      " [ 0.31968569 -0.20449415  0.92306525  0.01274198  0.92036808  0.18874456\n",
      "   0.39128868 -0.66008237  0.5831034  -1.85397813]\n",
      " [ 0.51001892 -0.29599811 -0.6537802  -0.30329211  0.70337451 -0.30264679\n",
      "  -1.29771583 -0.11803858 -0.43844685 -1.29468378]]\n",
      "Device\n",
      "cpu\n",
      "Shape\n",
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Create tensor from numpy array:\n",
    "\n",
    "X = np.random.normal(0,1,(10,10))\n",
    "X = torch.tensor(X, dtype=torch.float64)\n",
    "\n",
    "\n",
    "print('Element of a tensor:')\n",
    "print(X[0,0])\n",
    "print('Numpy content')\n",
    "print(X.numpy())\n",
    "print('Device')\n",
    "print(X.device)\n",
    "print('Shape')\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations on tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of two tensors:\n",
      "tensor([[11., 13., 15.],\n",
      "        [17., 19., 21.],\n",
      "        [23., 25., 27.]], dtype=torch.float64)\n",
      "Tensor multiplication:\n",
      "tensor([[ 84.,  90.,  96.],\n",
      "        [201., 216., 231.],\n",
      "        [318., 342., 366.]], dtype=torch.float64)\n",
      "Tensor transpose:\n",
      "tensor([[ 84., 201., 318.],\n",
      "        [ 90., 216., 342.],\n",
      "        [ 96., 231., 366.]], dtype=torch.float64)\n",
      "Tensor multiplication:\n",
      "tensor([[ 84.,  90.,  96.],\n",
      "        [201., 216., 231.],\n",
      "        [318., 342., 366.]], dtype=torch.float64)\n",
      "Mean:\n",
      "tensor(5., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.tensor(np.arange(1,10).reshape(3,3), dtype=torch.float64)\n",
    "b = torch.tensor(np.arange(10,19).reshape(3,3), dtype=torch.float64)\n",
    "\n",
    "print('Sum of two tensors:')\n",
    "print(a+b)\n",
    "print('Tensor multiplication:')\n",
    "print(a @ b)\n",
    "print('Tensor transpose:')\n",
    "print((a @ b).T)\n",
    "print('Tensor multiplication:')\n",
    "print(torch.matmul(a,b))\n",
    "print('Mean:')\n",
    "print(torch.mean(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inline operators have a _ in the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]], dtype=torch.float64)\n",
      "tensor([[1., 4., 7.],\n",
      "        [2., 5., 8.],\n",
      "        [3., 6., 9.]], dtype=torch.float64)\n",
      "tensor([[ 6.,  9., 12.],\n",
      "        [ 7., 10., 13.],\n",
      "        [ 8., 11., 14.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "a.transpose_(0,1)\n",
    "print(a)\n",
    "a.add_(5.0)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]], dtype=torch.int32)\n",
      "tensor([[4, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]], dtype=torch.int32)\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# In CPU\n",
    "a = np.arange(1,10).reshape(3,3)\n",
    "print(a)\n",
    "t = torch.from_numpy(a)\n",
    "print(t)\n",
    "a[0,0] = 4\n",
    "print(t)\n",
    "\n",
    "tt = torch.ones(3,3)\n",
    "\n",
    "print(tt)\n",
    "\n",
    "nn = tt.numpy()\n",
    "\n",
    "nn[0,0] = 5.0\n",
    "\n",
    "print(tt)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "To implement a custom dataset, we use simulated data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000\n",
    "ep = 0.1\n",
    "\n",
    "x = np.random.uniform(-4*np.pi,4*np.pi,(num,2))\n",
    "\n",
    "y = np.sin(np.sqrt(x[:,0]**2+x[:,1]**2))+ ep*np.random.normal(0,1,num)\n",
    "\n",
    "\n",
    "np.save('../DATA/x.npy', x)\n",
    "np.save('../DATA/y.npy', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_file, y_file):\n",
    "        # Class constructor:\n",
    "        self.x = np.load(x_file)\n",
    "        self.y = np.load(y_file)\n",
    "        self.len = self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieves an item from the dataset:\n",
    "        return self.x[index], self.y[index]\n",
    "        # TODO: convert to tensor \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Returns the length of the dataset:\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-5.0624608 ,  4.91559774]), 0.6958001151097415)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = CustomDataset('../DATA/x.npy', '../DATA/y.npy')\n",
    "\n",
    "data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a sequential NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNNTest(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call the parent class constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNNTest(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNNTest().double()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 2]) | Values : tensor([[ 0.0804,  0.4670],\n",
      "        [-0.3912, -0.0872]], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.5305,  0.0899], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0031, -0.0121, -0.0227,  ...,  0.0274,  0.0266, -0.0228],\n",
      "        [-0.0186,  0.0263,  0.0003,  ..., -0.0039,  0.0016, -0.0199]],\n",
      "       dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0204, 0.0169], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([1, 512]) | Values : tensor([[ 1.5638e-02,  2.2203e-02,  1.8166e-02,  3.8535e-02, -5.6893e-03,\n",
      "         -2.1577e-02, -2.0472e-02, -6.2811e-03, -4.0958e-02, -2.3156e-02,\n",
      "         -3.8314e-02, -2.9775e-02,  8.4635e-03,  1.5029e-02,  3.0583e-02,\n",
      "          1.2054e-02, -5.1044e-03, -3.7807e-02,  1.1522e-02, -2.6853e-02,\n",
      "         -3.4920e-02, -2.3160e-02,  2.5789e-03, -2.3710e-02, -4.4019e-02,\n",
      "          4.0169e-03,  2.7889e-02, -4.0557e-02,  5.4816e-03,  2.6710e-02,\n",
      "          1.1795e-02, -4.2958e-02,  3.6341e-02, -3.9947e-02, -4.0016e-02,\n",
      "          2.9425e-02,  1.4727e-02, -2.2340e-02, -9.0552e-03,  9.3193e-03,\n",
      "         -8.9367e-03,  1.2350e-02,  1.4789e-02, -2.4779e-02, -2.7110e-02,\n",
      "         -4.0748e-02,  3.4567e-02,  3.0228e-02,  3.9603e-03, -2.7387e-02,\n",
      "         -1.4529e-02,  3.9575e-02,  7.2643e-03, -3.5842e-02,  1.8336e-03,\n",
      "         -3.1798e-03,  2.3724e-02, -3.1907e-02,  1.2452e-02,  3.3247e-02,\n",
      "          1.9651e-02,  6.6801e-03, -3.6344e-02, -1.2204e-02,  2.9520e-02,\n",
      "          1.5366e-02,  1.6368e-02, -4.8107e-03, -1.5412e-02, -8.6038e-03,\n",
      "          2.2118e-02, -1.5468e-02,  3.3324e-02,  2.2193e-02,  1.5436e-02,\n",
      "          7.8318e-04, -2.3122e-03, -1.0110e-02,  2.4672e-02, -3.0699e-02,\n",
      "         -4.2543e-02, -3.6629e-02,  4.3544e-02, -1.8896e-02, -2.5833e-02,\n",
      "          7.1202e-03,  2.5052e-02,  8.7663e-03, -2.0192e-02,  1.3228e-02,\n",
      "          2.4093e-02,  3.0951e-02, -2.7789e-03,  6.7999e-03,  3.8102e-02,\n",
      "          7.3336e-03, -2.1360e-02,  2.2547e-02, -2.7941e-03, -1.1953e-02,\n",
      "         -1.1188e-03, -1.8241e-02, -2.2477e-02,  1.7912e-02,  2.0358e-02,\n",
      "          3.7945e-02, -2.6648e-02, -1.5625e-02,  2.2631e-02,  2.4467e-02,\n",
      "         -1.1632e-02,  2.0783e-02, -4.2783e-02, -3.6957e-02,  3.4025e-02,\n",
      "          3.8103e-02, -1.6782e-02,  8.7486e-03,  3.3244e-02,  2.7019e-02,\n",
      "          4.1207e-03, -4.3463e-02, -2.6847e-02,  4.2314e-02, -1.0915e-03,\n",
      "         -3.8148e-02, -2.5436e-02,  3.9985e-02, -2.6600e-02,  2.7235e-02,\n",
      "          1.3065e-05, -2.5685e-02, -1.9013e-02, -4.1718e-02,  3.9523e-02,\n",
      "          2.6837e-02,  1.3354e-02,  1.0973e-02, -3.9311e-02,  2.8614e-03,\n",
      "         -3.2864e-02, -2.5972e-02,  4.7896e-04,  1.2131e-02,  3.9726e-02,\n",
      "         -3.1753e-02,  4.4094e-02,  3.3461e-02, -4.7088e-03, -4.9675e-03,\n",
      "          1.7318e-02,  2.4820e-02,  1.8982e-02,  3.5272e-02,  2.8147e-02,\n",
      "         -1.1265e-02,  1.2649e-02,  3.1975e-02, -2.9293e-02,  9.5652e-03,\n",
      "         -1.2593e-02,  2.1954e-02, -3.9411e-02,  5.3918e-03, -2.8018e-02,\n",
      "         -2.2988e-02,  1.3791e-02,  1.8858e-02,  3.2395e-02, -1.3607e-02,\n",
      "         -3.7441e-02,  2.4100e-02, -1.4786e-02,  3.0663e-03,  2.3326e-02,\n",
      "          6.2712e-03, -3.2623e-02, -5.4173e-03, -2.8245e-02,  4.0033e-02,\n",
      "         -6.0729e-03, -1.9764e-02,  2.2526e-03,  2.2559e-02,  4.1558e-03,\n",
      "          5.4652e-03, -3.2067e-02,  2.2335e-02, -1.3798e-03, -5.7817e-03,\n",
      "         -4.0459e-02, -1.6622e-02,  2.2014e-02, -4.2344e-02, -3.9177e-02,\n",
      "         -3.5521e-02,  1.7586e-03,  1.3586e-02,  1.9361e-02, -1.2452e-02,\n",
      "         -1.6587e-02, -3.1817e-02, -1.4046e-02,  9.9943e-03, -9.4224e-04,\n",
      "          7.5586e-03,  6.5827e-03, -2.7883e-02,  3.9126e-02, -3.8855e-02,\n",
      "          3.5761e-02, -1.7509e-02, -1.6839e-02, -2.7711e-02,  3.8173e-02,\n",
      "         -3.6604e-02, -1.7374e-02, -1.7447e-02,  2.2446e-03, -1.6367e-02,\n",
      "         -9.7358e-04,  2.1339e-02,  1.9591e-02,  1.6093e-02,  1.9711e-02,\n",
      "         -2.8569e-02,  2.2253e-02,  1.0997e-02,  2.0582e-02,  1.0965e-02,\n",
      "         -3.2577e-02, -3.9893e-02, -1.3482e-02, -2.2527e-02,  1.3635e-02,\n",
      "         -1.1276e-02,  1.6503e-02,  1.8495e-02,  1.8262e-03,  3.3221e-03,\n",
      "         -3.1363e-03, -1.2715e-03, -5.5239e-03, -2.5083e-02, -5.5643e-03,\n",
      "          7.5674e-03,  3.8184e-02, -3.7404e-02, -3.5297e-03,  2.3332e-03,\n",
      "          1.6429e-02,  4.3843e-02, -3.4740e-02,  3.7642e-03, -4.0939e-02,\n",
      "          2.4778e-02,  2.5743e-02, -2.8698e-02,  3.4658e-02,  3.4527e-02,\n",
      "          1.4030e-02,  3.6589e-02, -1.0394e-02, -3.6880e-02,  7.0319e-03,\n",
      "         -7.7680e-03,  3.3844e-02, -1.6250e-02,  1.1205e-02,  1.9077e-02,\n",
      "          2.9661e-02,  3.4506e-02,  8.4871e-03, -4.2636e-02,  2.2216e-02,\n",
      "         -4.0187e-02, -1.4525e-02, -1.5429e-02,  2.9616e-02,  2.2079e-02,\n",
      "          4.4651e-03,  2.9380e-02, -6.5174e-03,  3.4676e-02, -4.2763e-02,\n",
      "          1.0866e-02, -1.2325e-02,  2.3087e-02, -3.8414e-02, -8.7160e-03,\n",
      "          3.4155e-02,  2.1601e-02,  3.6357e-02, -2.8735e-02,  1.1002e-02,\n",
      "          2.7432e-02,  3.2216e-02, -2.3289e-03,  1.4442e-02,  2.0875e-03,\n",
      "         -4.2140e-02, -4.2252e-02, -4.3271e-02,  1.7636e-02,  2.4230e-02,\n",
      "         -3.1569e-02,  2.0239e-02, -3.4483e-02, -1.3331e-02, -2.6731e-02,\n",
      "         -2.9110e-02, -1.1519e-02,  1.0620e-02,  2.8747e-02,  8.1205e-03,\n",
      "          2.7499e-02,  4.2291e-03,  4.1806e-02, -1.4192e-02, -3.2263e-02,\n",
      "         -3.0049e-02,  1.8015e-03, -4.9114e-03,  9.3770e-03,  6.8748e-04,\n",
      "         -2.7542e-02, -1.5957e-02, -4.2211e-02, -1.6519e-02,  3.4884e-03,\n",
      "          2.6656e-02,  5.7525e-03, -4.4099e-03,  1.5283e-02, -3.1040e-02,\n",
      "          1.4489e-03,  2.7678e-02, -3.1309e-02,  2.2475e-02,  3.3416e-02,\n",
      "          2.6132e-02, -2.7735e-02,  2.9087e-02, -3.9817e-02, -3.4372e-02,\n",
      "          2.7388e-02, -1.2895e-02,  1.3835e-03,  2.7013e-03, -3.4486e-03,\n",
      "         -1.9446e-02,  2.8655e-02,  3.4184e-02,  1.1860e-02, -2.6471e-02,\n",
      "         -2.3399e-02, -4.4105e-02, -1.3015e-02, -1.9717e-02, -1.2016e-02,\n",
      "          3.1175e-03,  1.3894e-03,  5.0455e-03, -3.9786e-02, -3.7484e-02,\n",
      "         -1.9611e-02,  3.3330e-02, -2.5845e-03,  2.0455e-02,  3.7124e-02,\n",
      "         -2.0224e-02, -1.9661e-02,  1.5995e-02,  4.9301e-03, -1.3687e-02,\n",
      "          4.1088e-02,  4.2272e-02,  8.1543e-03,  1.9431e-02, -7.8989e-03,\n",
      "          3.5535e-02, -3.3289e-02, -7.2028e-03,  3.5505e-02, -3.4530e-02,\n",
      "         -1.3136e-02, -2.9284e-02,  3.1468e-02, -2.6262e-02, -2.7614e-03,\n",
      "          3.7595e-02,  1.4810e-02, -8.4751e-03,  4.1065e-02,  3.8677e-02,\n",
      "         -2.9955e-02, -3.8333e-02,  1.4393e-03, -3.4025e-02,  3.8499e-02,\n",
      "          3.2449e-02,  6.7560e-04, -1.9681e-02, -2.0133e-04,  1.6374e-02,\n",
      "         -5.5837e-03, -3.9984e-02,  7.6874e-03, -1.1809e-02, -1.7331e-02,\n",
      "          3.3896e-03, -2.7588e-02,  3.7037e-02,  4.2969e-02, -4.2010e-02,\n",
      "          1.5697e-02, -3.3711e-02, -4.2995e-02, -2.0998e-02,  2.8176e-02,\n",
      "          8.9750e-03,  3.0033e-02, -1.8754e-02, -3.1406e-02, -2.2781e-02,\n",
      "          2.8684e-02,  3.2705e-03, -3.7435e-02, -1.3227e-02,  1.5486e-02,\n",
      "         -2.4089e-02, -2.5119e-02, -2.5972e-02, -3.8644e-02, -3.7789e-02,\n",
      "         -2.9190e-02,  8.0274e-03,  4.0837e-02,  2.4016e-02,  1.2828e-02,\n",
      "         -4.0730e-02, -1.2261e-02,  4.2992e-02, -1.2739e-02, -3.4042e-03,\n",
      "          3.1904e-02, -4.2484e-02, -1.7028e-02,  1.1389e-02, -2.5655e-02,\n",
      "         -1.4202e-02, -3.1460e-02,  4.1943e-02,  1.7631e-02, -1.6295e-02,\n",
      "         -7.7039e-03,  2.2355e-02,  2.0196e-02,  6.0120e-03, -4.3627e-02,\n",
      "         -1.2571e-02,  1.9163e-02,  2.2702e-02, -1.3444e-02,  3.9612e-02,\n",
      "         -2.2430e-03,  2.4359e-02, -9.5678e-03,  3.5448e-02,  3.3345e-02,\n",
      "          1.8991e-02, -1.6967e-02,  1.6675e-02, -5.7031e-04,  4.2621e-02,\n",
      "          1.0740e-02,  3.7812e-02, -2.2498e-02, -6.2188e-03,  3.2188e-02,\n",
      "          3.4682e-02, -3.6354e-02,  2.9790e-02,  4.0280e-02, -3.8731e-02,\n",
      "         -3.3568e-02, -1.8971e-02, -2.3655e-02, -1.0951e-03,  3.4819e-02,\n",
      "          1.1080e-02,  5.2965e-03, -1.1479e-03, -3.8494e-02, -1.7983e-02,\n",
      "         -4.3386e-02, -6.5551e-03,  1.7001e-02, -4.2301e-02, -1.9669e-02,\n",
      "         -1.4900e-02, -9.6196e-04, -3.4236e-02, -9.5757e-03, -4.4034e-02,\n",
      "         -5.2340e-03, -2.5102e-03,  2.4288e-02,  1.2804e-02, -1.6935e-02,\n",
      "         -3.1772e-02, -2.0379e-02]], dtype=torch.float64,\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([1]) | Values : tensor([-0.0188], dtype=torch.float64, grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0804,  0.4670],\n",
       "        [-0.3912, -0.0872],\n",
       "        [ 0.2734,  0.2262],\n",
       "        ...,\n",
       "        [ 0.0681,  0.3311],\n",
       "        [-0.3613, -0.0013],\n",
       "        [-0.2722, -0.6667]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['linear_relu_stack.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 0.3 # error term\n",
    "num = 20000 #num poins\n",
    "\n",
    "X = np.random.uniform(-4*np.pi,4*np.pi, (num,1))\n",
    "Y = np.random.uniform(-4*np.pi,4*np.pi, (num,1))\n",
    "\n",
    "XXX = np.hstack((X,Y))\n",
    "\n",
    "Z = np.sin(np.sqrt(X**2+Y**2))+ ep*np.random.normal(0,1,(num,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d61ed46a50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(training_data[0][0].reshape(28,28).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m]\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[1;32mc:\\My_python\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:138\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data[0:64], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtrain_dataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "for batch, (X, y) in enumerate(train_dataloader[0]):\n",
    "    print(X.shape, y.shape)\n",
    "    plt.imshow(X[0].reshape(28,28).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1d61f07e290>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0+cpu'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
